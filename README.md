# Nonstationary-Multi-Armed-Bandits
The code below generates  chapter 2 of "Reinforcement Learning: An Introduction" by Andrew Barto and Richard S. Sutton. The main issue is the Nonstationary Multi-Armed Bandits problem, whcih is addressed through epsilon-greedy, UCB and and gradient bandit algorithms: in order to do so, the 10 armed testbed is introduced.

We will compare the performance of two different instances of the **Epsilon-Greedy algorithm**, one using **sample averages**, and the other using a **constant step size** alpha = 0.1.
Plot the **average reward**, the **cumulative average reward**, and the **average percentage of optimal actions**.
